## 문제
스케줄링(crantab) 로직 > 건수가 어마무시하게 많아져 로그 양이 많아져 로그 확인하기가 힘듦

### 로그 파일을 확인하려고 열다가 뻗거나 확인할 수 없을정도로 버벅임

## 원인
```
상태   |건수   |측정시간                 |
-----+-----+---------------------+
대기   |  981|2023-09-01 17:39:36.0|
진행   | 5794|2023-09-01 17:39:36.0|
성공   | 3277|2023-09-01 17:39:36.0|
실패   |    6|2023-09-01 17:39:36.0|
Total|10058|2023-09-01 17:39:36.0|
```

- 17:39 기준으로 `대기 + 진행 = 6775` 
- 조회를 6,775번을 진행하게 된다. 
- 이로인해서 오류 슬랙도 3번 나오게 됨 
	- status = 4로 update 하는데 3분 이상 걸린다는 이야기 ...
  -  동일한 Error Log 가 3번 나오는 현상 
- 일단 3번 나오는건 패스 하더라도 ...  (5분으로 늘리고 싶은데 일단 내비두라고 .. )

### 여기서 제일 큰 문제는 
**로그 파일 크기가 너무 크다! 10GB는 말이 안되잖아 😡** 
- 수가 많아지면 용량이 더 커질 수 있음.

#### <b style="color: red;">아무튼 로그파일 크기가 너무 커서  파일을 열다가 뻗는다.</b>
- linux> vim, cat, tail 등으로 확인 하기에도 너무 ....답답함.
- (회사PC) windows로 복사하여 로그 보는것도 더 뻗는다. 일단 다운로드 조차 너무 오래 걸림



## 해결? 

#### 우선 Laravel Log 자체 기능으로 용량별로 자체적으로 파일이 쪼개서 기록하는 기능이 있는지 확인해 보았지만 찾지 못하였음.

### split으로 파일 쪼개서 다운로드 받거나 리눅스에서 직접 확인.

#### 라인 수 확인 
`wc -l e_g-2023-09-01.log`
> 117863900 e_g-2023-09-01.log

#### 용량 확인 
`ll -h | grep e_g-2023-09-01.log`
> 4.4G  9월  1 16:37 e_g-2023-09-01.log

#### .e.g
`ll -h | grep e_g-2023-08-29.log`
> 2.5G (2606746302)

`wc -l e_g-2023-08-29.log`
> 74186319 line

라인당 35.13783049405646 bytes (약 35 byte)


#### 파일 용량 기준으로 나누기 
``` zsh
split -b 500m e_g-2023-08-29.log
```
> 500MB 기준, e_g-2023-08-29.log 파일을 나눈다.

- 결과
![[Pasted image 20230901165846.png]]

- 파일명을 승계하진 않는다.
- -- 접두사 옵션 `-a` 를 붙이면 ?? --
```zsh
split -b 500m e_g-2023-08-29.log e_g_2023-08-29
```
> 500MB 기준으로 나누는데, e_g-2023-08-29.log 파일을 e_g_2023-08-29 라는 접두사를 붙인다.
#### 라인 수 기준으로 나누기
``` zsh
split -l 1000000 e_g-2023-08-29.log
```
> 백만라인 기준으로 나눈다.




#### linux > windows file 복사
`scp {user}@{ip}:{파일경로} {windows 받을 경로}`

- 500MB | 5.3MB/s | 01:35 
  - 500MB 기준으로 1분 35초 걸림
- `-r` 옵션으로 디렉터리 복사 가능 
- 애초에 split 할 때 디렉터리 만들고 그 안에서 쪼개지게 하면 될 듯?

#### 마무리로 삭제가 자동으로 안될것이기 때문에 직접 삭제 🤔
 
``` zsh
# e.g
rm -rf ./xaa
```
